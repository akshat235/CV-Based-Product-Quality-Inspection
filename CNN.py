# -*- coding: utf-8 -*-
"""IP31-CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VLTZDmpLM-BCRepqQASBHyczPrV0NkQF

### Importing
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import shutil
import random
import itertools
import numpy as np
import pandas as pd
from PIL import Image
from skimage import io
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.layers import Activation, Dense, Flatten, Conv2D, MaxPool2D, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img
# %matplotlib inline

def plot_cm(cm, classes, normalize = False , title = 'Confusion Matrix', cmap = plt.cm.Blues):
  plt.imshow(cm, interpolation = 'nearest', cmap = cmap)
  plt.title(title)
  plt.colorbar()
  tick_marks = np.arange (len(classes))
  plt.xticks(tick_marks, classes, rotation = 45)
  plt.yticks(tick_marks, classes)

  if normalize:
    cm = cm.astype('float')/cm.sum(axis =1)[:,np.newaxis]
    print("Normalized CM")
  else:
    print ('Confusion Matrix, without normalization')
  print(cm)

  thresh  = cm.max()/2
  for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j,i,cm[i,j],horizontalalignment = 'center', color = 'white' if cm[i,j]>thresh else"black")

  plt.tight_layout()
  plt.ylabel('True Label')
  plt.xlabel('Predicted Label')

!gdown --id "1-txGiJZhCBQJs6a7XtEc7_7CmpbN86Tz"

!unzip *zip



"""###Organizing"""

data300 = 'casting_data/casting_data'
train_dir = data300+'/train'
test_dir = data300+'/test'
val_dir = data300 + '/validation'

val_ok = data300 + '/validation/ok_front'
val_def = data300 + '/validation/def_front'

train_def_300 = data300+'/train/def_front'
train_ok_300 = data300+'/train/ok_front'

test_def_300 = data300+'/test/def_front'
test_ok_300 = data300+'/test/ok_front'

print(' No. of images in train_def_300 : ', len(os.listdir(train_def_300)))
print(' No. of images in train_ok_300 :  ' , len(os.listdir(train_ok_300)))

print(' No. of images in test_def_300 :  ', len(os.listdir(test_def_300)))
print(' No. of images in test_ok_300 :   ', len(os.listdir(test_ok_300)))

temp1 = 0
temp2 = 0
os.makedirs(val_def)
os.makedirs(val_ok)

#moving 654 images to val_ok

if temp1 ==0:
  for i in range(654):
    img_name = random.choice(os.listdir(train_ok_300))
    img_path = train_ok_300+'/'+img_name 
    shutil.move(img_path, val_ok+'/'+img_name)
    temp1 +=1
else:
  print('already performed this operation')

#moving 1090 images to val_def

if temp2 ==0:
  for i in range(1090):
    img_name = random.choice(os.listdir(train_def_300))
    img_path = train_def_300+'/'+img_name 
    shutil.move(img_path, val_def+'/'+img_name)
    temp1 +=1
else:
  print('already performed this operation')

assert len(os.listdir(val_def)) == 1090
assert len(os.listdir(val_ok)) == 654

"""###Model"""



train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = train_dir ,
                                                                 target_size = (300,300), classes = ['def_front','ok_front'], batch_size =32)

validation_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = val_dir,
                                                    target_size = (300,300), classes = ['def_front','ok_front'], batch_size =32)

test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = test_dir,
                                      target_size = (300,300), classes = ['def_front','ok_front'], batch_size =32, shuffle = False)

# model = Sequential(
#     [Conv2D(filters=32, input_shape= (300,300,3), kernel_size=(3,3), padding = 'same', activation='relu'),
#      MaxPool2D(pool_size=(2,2), strides=2),
#      Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
#      MaxPool2D(pool_size=(2,2), strides=2),
#      Dropout(0.2),
#      Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation='relu'),
#      MaxPool2D(pool_size=(2,2), strides=2),
#      Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
#      MaxPool2D(pool_size=(2,2), strides=2),
#      Flatten(),
#      Dense(units =2, activation = 'softmax')])

"""####1"""

model = Sequential(
    [Conv2D(filters=32, input_shape= (300,300,3), kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Dropout(0.2),
     Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
    #  Conv2D(filters=32, kernel_size=(3,3), padding = 'same', activation='relu'),
    #  MaxPool2D(pool_size=(2,2), strides=2),
     Flatten(),
     Dense(units =2, activation = 'sigmoid')])

model.summary()

model.compile(optimizer=Adam(), loss = 'binary_crossentropy', metrics=['accuracy'])

# keras.utils.plot_model(model, show_shapes=True)

hist = model.fit(x= train_batches ,validation_data =validation_batches , verbose=1, epochs =15)

pd.DataFrame(hist.history).plot(figsize=(10,6))
plt.show()

test_img, testlabel = next(test_batches)
len(test_batches.classes)

predictions = model.predict(x=test_batches, verbose =1)

cm = confusion_matrix(y_true = test_batches.classes, y_pred = np.argmax(predictions, axis=-1))

plot_cm(cm, classes = ['defective', 'ok'])





"""####2"""

model = Sequential(
    [Conv2D(filters=32, input_shape= (300,300,3), kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Dropout(0.2),
     Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
    #  Conv2D(filters=32, kernel_size=(3,3), padding = 'same', activation='relu'),
    #  MaxPool2D(pool_size=(2,2), strides=2),
     Flatten(),
     Dense(units =2, activation = 'softmax')])

model.summary()

model.compile(optimizer=Adam(), loss = 'categorical_crossentropy', metrics=['accuracy'])

# keras.utils.plot_model(model, show_shapes=True)

hist = model.fit(x= train_batches ,validation_data =validation_batches , verbose=1, epochs =15)

pd.DataFrame(hist.history).plot(figsize=(10,6))
plt.show()

test_img, testlabel = next(test_batches)
len(test_batches.classes)

predictions = model.predict(x=test_batches, verbose =1)

cm = confusion_matrix(y_true = test_batches.classes, y_pred = np.argmax(predictions, axis=-1))

plot_cm(cm, classes = ['defective', 'ok'])



"""####3"""

model2=0

model2 = Sequential(
    [Conv2D(filters=32, input_shape= (300,300,3), kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Conv2D(filters=128, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
     Conv2D(filters=64, kernel_size=(3,3), padding = 'same', activation='relu'),
     MaxPool2D(pool_size=(2,2), strides=2),
    #  Conv2D(filters=32, kernel_size=(3,3), padding = 'same', activation='relu'),
    #  MaxPool2D(pool_size=(2,2), strides=2),
     Flatten(),
     Dense(units =2, activation = 'sigmoid')])

model2.compile(optimizer=Adam(), loss = 'binary_crossentropy', metrics=['accuracy'])

hist2 = model2.fit(x= train_batches ,validation_data =validation_batches , verbose=1, epochs =10)

pd.DataFrame(hist2.history).plot(figsize=(10,6))
plt.show()

test_img, testlabel = next(test_batches)

predictions2 = model2.predict(test_batches,verbose=1)

np.round(predictions2)

cm = confusion_matrix(y_true = test_batches.classes, y_pred = np.argmax(predictions2, axis=-1))
plot_cm(cm, classes = ['def', 'ok'])

model2.summary()





"""####dsa

"""

for i in range(20):
    folder = random.choice(os.listdir(test_dir))
    img_name = random.choice(os.listdir(test_dir+'/'+folder))
    img_path = test_dir+'/'+folder+'/'+img_name
    img = plt.imread(img_path)
    plt.imshow(img)

test_batches

test_batches_plot = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory = test_dir,
                                      target_size = (300,300), classes = ['def_front','ok_front'], batch_size =20)

batch = next(test_batches_plot)

j=1
plt.figure(figsize=(15,16))
for i in batch[0]:
  img = array_to_img(i)
  plt.subplot(5,4,j)
  plt.axis('off')
  plt.title(j)
  plt.text(0,0,j,fontsize =10)
  plt.imshow(img)
  j+=1

